{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c0473d-793c-4639-9dbb-3b02bf6c9131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 11:48:12.314976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747561692.355076    7416 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747561692.365905    7416 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-18 11:48:12.401310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import random as python_random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffdd5e0e-2817-4bbc-a7ac-d3306e61378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = pd.read_csv(\"hosp/admissions.csv\")\n",
    "patients = pd.read_csv(\"hosp/patients.csv\")\n",
    "diagnoses = pd.read_csv(\"hosp/diagnoses_icd.csv\")\n",
    "icustays = pd.read_csv(\"icu/icustays.csv\")\n",
    "#chartevents = pd.read_csv(\"icu/chartevents.csv\", chunksize=250000)  # Adjusted chunk size\n",
    "labevents = pd.read_csv(\"hosp/labevents.csv\")\n",
    "discharge = pd.read_csv(\"discharge.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31a7163-e129-44c0-a891-5870c6f1bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discharge = pd.read_csv(\"discharge.csv\")\n",
    "LVEF = discharge[discharge['text'].str.contains(r'LVEF')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5ce07f-166f-401e-a09e-102b2696666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               note_id  subject_id   hadm_id note_type  note_seq  \\\n",
      "9       10000764-DS-11    10000764  27897940        DS        11   \n",
      "10      10000826-DS-17    10000826  20032235        DS        17   \n",
      "18      10000980-DS-20    10000980  29654838        DS        20   \n",
      "19      10000980-DS-21    10000980  26913865        DS        21   \n",
      "24      10000980-DS-26    10000980  20897796        DS        26   \n",
      "...                ...         ...       ...       ...       ...   \n",
      "331782  19999784-DS-22    19999784  29889147        DS        22   \n",
      "331783  19999784-DS-23    19999784  29956342        DS        23   \n",
      "331784  19999784-DS-24    19999784  24755486        DS        24   \n",
      "331790  19999840-DS-20    19999840  26071774        DS        20   \n",
      "331792   19999987-DS-2    19999987  23865745        DS         2   \n",
      "\n",
      "                  charttime            storetime         text  \n",
      "9       2132-10-19 00:00:00  2132-10-19 18:50:00          NaN  \n",
      "10      2146-12-12 00:00:00  2146-12-12 18:22:00    LVEF >55%  \n",
      "18      2188-01-05 00:00:00  2188-01-06 20:49:00  LVEF 50-55%  \n",
      "19      2189-07-03 00:00:00  2189-07-03 19:50:00          NaN  \n",
      "24      2193-08-17 00:00:00  2193-08-17 16:05:00     LVEF 50%  \n",
      "...                     ...                  ...          ...  \n",
      "331782  2120-10-31 00:00:00  2120-10-31 11:53:00    LVEF >55%  \n",
      "331783  2121-02-05 00:00:00  2121-02-05 17:34:00    LVEF >55%  \n",
      "331784  2121-06-05 00:00:00  2121-06-05 07:04:00    LVEF >55%  \n",
      "331790  2164-07-28 00:00:00  2164-07-29 14:52:00    LVEF >55%  \n",
      "331792  2145-11-11 00:00:00  2145-11-11 13:13:00     LVEF 55%  \n",
      "\n",
      "[50894 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#LVEF_per = LVEF_new['text'].str.findall(r'LVEF.+?(?=%)')\n",
    "#print(LVEF_per)\n",
    "#LVEF_per = LVEF_new.loc[LVEF_new['text'].str.contains(r'LVEF.+?%', na=False)]\n",
    "#print(LVEF_per)\n",
    "LVEF_per = LVEF.copy()\n",
    "LVEF_per['text'] = LVEF_per['text'].str.extract(r'(LVEF.+?%)')\n",
    "print(LVEF_per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca3d9ac-3c5b-4533-af25-43c76cbeaae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "55    20087\n",
      "60      404\n",
      "75      225\n",
      "65      210\n",
      "70      130\n",
      "50       68\n",
      "40       10\n",
      "45        5\n",
      "47        2\n",
      "43        1\n",
      "20        1\n",
      "64        1\n",
      "30        1\n",
      "32        1\n",
      "80        1\n",
      "71        1\n",
      "25        1\n",
      "58        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LVEF_gt = LVEF_per.copy()\n",
    "LVEF_gt['text'] = LVEF_gt['text'].str.extract(r'(>.*[0-9]*)')\n",
    "LVEF_gt = LVEF_gt.dropna(subset=['text'])\n",
    "#print(LVEF_gt)\n",
    "#print(LVEF_gt['text'].unique())\n",
    "LVEF_gt['text'] = LVEF_gt['text'].str.extract(r'([0-9]+)')\n",
    "#print(LVEF_gt['text'].unique())\n",
    "gt_values = LVEF_gt.text.value_counts()\n",
    "print(gt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d97980-a019-46e7-9d51-2ff7d134bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<20' '< 20' '<40' '<35' '<30' '< 10' '<<20' '<' '< 30' '<10' '< 15'\n",
      " '<25' '< 40' '<15' '<<10' '< 25' '< 45']\n",
      "['20' '40' '35' '30' '10' nan '15' '25' '45']\n",
      "text\n",
      "20    144\n",
      "30     25\n",
      "40     12\n",
      "10      8\n",
      "25      8\n",
      "15      7\n",
      "35      4\n",
      "45      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LVEF_lt = LVEF_per.copy()\n",
    "LVEF_lt['text'] = LVEF_lt['text'].str.extract(r'(<[<]*[ ]*[0-9]*)')\n",
    "LVEF_lt = LVEF_lt.dropna(subset=['text'])\n",
    "#print(LVEF_lt)\n",
    "print(LVEF_lt['text'].unique())\n",
    "LVEF_lt['text'] = LVEF_lt['text'].str.extract(r'([0-9]+)')\n",
    "print(LVEF_lt['text'].unique())\n",
    "lt_values = LVEF_lt.text.value_counts()\n",
    "print(lt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40eb1bbb-015d-4af5-97d7-35e9c1f92e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['= ? 35-40' '= 25' '= 40-45' '= 64' '= 35-40' '= 65' '= 45-50' '= 59'\n",
      " '= 20' '= 68' '= 40' '= 35' '= 61' '= 79' '= 55' '= 60' '= 26' '= 15'\n",
      " '=45' '= 46' '= 40 - 45' '= 50-55' '= 72' '= 63' '= 41' '= 50' '= 21'\n",
      " '= 30' '= 45' '= 70' '=75' '= 13' '=25' '=64' '= 58' '= 36' '= 47' '= 53'\n",
      " '=40' '= 71' '= 52' '=55' '= 69' '= 57' '= 17' '= 56' '= 29' '=63' '=42'\n",
      " '= 62' '= 44' '= 55-60' '= 30 - 35' '=50' '= ? 40' '=59' '=55-60' '= 43'\n",
      " '=40-45' '= 27' '= 10 - 15' '= 67' '= <20' '= 20 - 25' '=70' '= 49'\n",
      " '= 33' '= 48' '=56' '= 15 - 20' '= 38' '=65' '=50-60' '= 45 - 50' '= 54'\n",
      " '=60' '= 60-65' '= 22' '= 25 - 30' '=30' '= 40-50' '= 37' '= 23'\n",
      " '= 15*-20' '= 42' '= >55' '= 24' '= 10' '=20' '= 66' '= 75' '= 34' '= 73'\n",
      " '= 3040' '= 14' '=58' '= 32' '=35' '= 19' '=30 to 40' '= ? 30' '= 74'\n",
      " '= 60-70' '= ?45-50' '= 77' '= ?40' '= 35- 40' '= 31' '= ?45' '= ~50'\n",
      " '= 35-45' '= < 10' '= 51' '= 50 - 55' '=45-50' '= 65-70' '=53' '= >60'\n",
      " '= 25 -30' '= 28' '= 45 to 50' '= 80' '= 78' '= 35 to 40' '= 39'\n",
      " '= X35-40' '=69' '=65=70' '=<<20' '= 35 - 40' '=70-75' '= 025-30'\n",
      " '=35-40' '= 18' '=60-65' '=33' '= 45=50' '=61' '= 76'\n",
      " '= ___ Cardiovascular ECHO 61' '= ~40' '= X61' '=50-55' '=<20' '=50-50'\n",
      " '=27' '= 55-602' '=38' '=~40-45' '= 25- 30' '= 81' '= 45--50' '= 40-55'\n",
      " '= 11' '= 12' '= X45-50' '= EF 40-45' '=<25' '= ?30' '=28' '= 70-80'\n",
      " '=15' '= 45 to 55' '= 16' '= <30' '=10' '= 20 -25' '= ?35' '=48'\n",
      " '= 25 to 35' '= ~45' '=74' '= 40 to 45' '= 40-35' '=45-55' '= 40=45'\n",
      " '= 45-55' '=29' '=65-70' '=45 - 50' '= 35-39' '= 75-80' '= ?60' '= 83'\n",
      " '= ~35' '= 40 -= 45' '=35- 40' '=49' '=73' '= 30 to 35' '= 40- 45'\n",
      " '= 740' '=72' '=44' '= 605' '= 40 -45' '= 15- 20' '= ~30' '= ? 40-45'\n",
      " '= 85' '=?40' '= ___ visually and 36' '=40-50' '=>60' '= ?20' '=71'\n",
      " '= ~60' '=68' '= 10 to 15' '= 35=-40' '=47' '= >75' '= 25*-30' '= 5'\n",
      " '=20 - 25' '= 82' '=30- 35']\n",
      "['35' '25' '40' '64' '65' '45' '59' '20' '68' '61' '79' '55' '60' '26'\n",
      " '15' '46' '50' '72' '63' '41' '21' '30' '70' '75' '13' '58' '36' '47'\n",
      " '53' '71' '52' '69' '57' '17' '56' '29' '42' '62' '44' '43' '27' '10'\n",
      " '67' '49' '33' '48' '38' '54' '22' '37' '23' '24' '66' '34' '73' '3040'\n",
      " '14' '32' '19' '74' '77' '31' '51' '28' '80' '78' '39' '025' '18' '76'\n",
      " '81' '11' '12' '16' '83' '740' '605' '85' '5' '82']\n",
      "text\n",
      "40     1301\n",
      "45     1261\n",
      "35      962\n",
      "50      689\n",
      "65      599\n",
      "       ... \n",
      "83        1\n",
      "740       1\n",
      "605       1\n",
      "85        1\n",
      "5         1\n",
      "Name: count, Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LVEF_et = LVEF_per.copy()\n",
    "LVEF_et['text'] = LVEF_et['text'].str.extract(r'(=.*[0-9])')\n",
    "LVEF_et = LVEF_et.dropna(subset=['text'])\n",
    "#print(LVEF_et)\n",
    "print(LVEF_et['text'].unique())\n",
    "LVEF_et['text'] = LVEF_et['text'].str.extract(r'([0-9]+)')\n",
    "print(LVEF_et['text'].unique())\n",
    "et_values = LVEF_et.text.value_counts()\n",
    "print(et_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb684ed-eb95-4dac-950c-559d14fc6d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count under 40: 4414\n",
      "Count between 40 and 50: 2218\n",
      "Count over 50: 24038\n"
     ]
    }
   ],
   "source": [
    "#print(gt_values, lt_values, et_values)\n",
    "under_40 = sum([\n",
    "    (LVEF_et['text'].astype(float) <= 40).sum(),\n",
    "    (LVEF_gt['text'].astype(float) <= 40).sum(),\n",
    "    (LVEF_lt['text'].astype(float) <= 40).sum()\n",
    "])\n",
    "\n",
    "between_40_50 = sum([\n",
    "    ((LVEF_et['text'].astype(float) > 40) & (LVEF_et['text'].astype(float) <= 50)).sum(),\n",
    "    ((LVEF_gt['text'].astype(float) > 40) & (LVEF_gt['text'].astype(float) <= 50)).sum(),\n",
    "    ((LVEF_lt['text'].astype(float) > 40) & (LVEF_lt['text'].astype(float) <= 50)).sum()\n",
    "])\n",
    "\n",
    "over_50 = sum([\n",
    "    (LVEF_et['text'].astype(float) > 50).sum(),\n",
    "    (LVEF_gt['text'].astype(float) > 50).sum(),\n",
    "    (LVEF_lt['text'].astype(float) > 50).sum()\n",
    "])\n",
    "\n",
    "print(f\"Count under 40: {under_40}\")\n",
    "print(f\"Count between 40 and 50: {between_40_50}\")\n",
    "print(f\"Count over 50: {over_50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8859b39a-e8b2-4615-9d99-e23cc0aed161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              note_id  subject_id   hadm_id note_type  note_seq  \\\n",
      "0      10002495-DS-13    10002495  24982426        DS        13   \n",
      "1      10004235-DS-21    10004235  24181354        DS        21   \n",
      "2      10004401-DS-27    10004401  29988601        DS        27   \n",
      "3      10004720-DS-11    10004720  22081550        DS        11   \n",
      "4      10005817-DS-11    10005817  20626031        DS        11   \n",
      "...               ...         ...       ...       ...       ...   \n",
      "30683   19810932-DS-3    19810932  29764035        DS         3   \n",
      "30684  19818243-DS-19    19818243  25296595        DS        19   \n",
      "30685   19968075-DS-2    19968075  28592225        DS         2   \n",
      "30686  19993336-DS-11    19993336  24615303        DS        11   \n",
      "30687  19993336-DS-12    19993336  23077223        DS        12   \n",
      "\n",
      "                 charttime            storetime text  \n",
      "0      2141-05-29 00:00:00  2141-05-30 02:29:00   35  \n",
      "1      2196-03-04 00:00:00  2196-03-06 10:57:00   25  \n",
      "2      2144-02-06 00:00:00  2144-02-06 10:07:00   40  \n",
      "3      2186-11-17 00:00:00  2186-11-18 20:37:00   64  \n",
      "4      2132-12-20 00:00:00  2132-12-20 12:07:00   35  \n",
      "...                    ...                  ...  ...  \n",
      "30683  2148-12-18 00:00:00  2148-12-18 22:20:00   20  \n",
      "30684  2144-03-07 00:00:00  2144-03-07 21:51:00   20  \n",
      "30685  2153-04-23 00:00:00  2153-04-25 02:31:00  NaN  \n",
      "30686  2171-09-12 00:00:00  2171-09-12 19:03:00   20  \n",
      "30687  2171-10-04 00:00:00  2171-10-04 19:10:00   20  \n",
      "\n",
      "[30688 rows x 8 columns]\n",
      "              note_id  subject_id   hadm_id note_type  note_seq  \\\n",
      "0      10002495-DS-13    10002495  24982426        DS        13   \n",
      "1      10004235-DS-21    10004235  24181354        DS        21   \n",
      "2      10004401-DS-27    10004401  29988601        DS        27   \n",
      "4      10005817-DS-11    10005817  20626031        DS        11   \n",
      "6      10010471-DS-21    10010471  21322534        DS        21   \n",
      "...               ...         ...       ...       ...       ...   \n",
      "30682  19769933-DS-16    19769933  26578430        DS        16   \n",
      "30683   19810932-DS-3    19810932  29764035        DS         3   \n",
      "30684  19818243-DS-19    19818243  25296595        DS        19   \n",
      "30686  19993336-DS-11    19993336  24615303        DS        11   \n",
      "30687  19993336-DS-12    19993336  23077223        DS        12   \n",
      "\n",
      "                 charttime            storetime text  \n",
      "0      2141-05-29 00:00:00  2141-05-30 02:29:00   35  \n",
      "1      2196-03-04 00:00:00  2196-03-06 10:57:00   25  \n",
      "2      2144-02-06 00:00:00  2144-02-06 10:07:00   40  \n",
      "4      2132-12-20 00:00:00  2132-12-20 12:07:00   35  \n",
      "6      2155-05-10 00:00:00  2155-05-14 19:50:00   45  \n",
      "...                    ...                  ...  ...  \n",
      "30682  2150-03-22 00:00:00  2150-03-22 23:59:00   20  \n",
      "30683  2148-12-18 00:00:00  2148-12-18 22:20:00   20  \n",
      "30684  2144-03-07 00:00:00  2144-03-07 21:51:00   20  \n",
      "30686  2171-09-12 00:00:00  2171-09-12 19:03:00   20  \n",
      "30687  2171-10-04 00:00:00  2171-10-04 19:10:00   20  \n",
      "\n",
      "[6632 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "LVEF_all = pd.concat([pd.concat([LVEF_et, LVEF_gt], ignore_index=True),LVEF_lt], ignore_index=True)\n",
    "print(LVEF_all)\n",
    "LVEF_under_50 = LVEF_all[LVEF_all['text'].astype(float) <= 50]\n",
    "print(LVEF_under_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f853fb-70c9-4487-aa77-4e2b76832646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              note_id  subject_id   hadm_id            charttime  \\\n",
      "0      10002495-DS-13    10002495  24982426  2141-05-29 00:00:00   \n",
      "1      10004235-DS-21    10004235  24181354  2196-03-04 00:00:00   \n",
      "2      10004401-DS-27    10004401  29988601  2144-02-06 00:00:00   \n",
      "4      10005817-DS-11    10005817  20626031  2132-12-20 00:00:00   \n",
      "6      10010471-DS-21    10010471  21322534  2155-05-10 00:00:00   \n",
      "...               ...         ...       ...                  ...   \n",
      "30682  19769933-DS-16    19769933  26578430  2150-03-22 00:00:00   \n",
      "30683   19810932-DS-3    19810932  29764035  2148-12-18 00:00:00   \n",
      "30684  19818243-DS-19    19818243  25296595  2144-03-07 00:00:00   \n",
      "30686  19993336-DS-11    19993336  24615303  2171-09-12 00:00:00   \n",
      "30687  19993336-DS-12    19993336  23077223  2171-10-04 00:00:00   \n",
      "\n",
      "                 storetime text  \n",
      "0      2141-05-30 02:29:00   35  \n",
      "1      2196-03-06 10:57:00   25  \n",
      "2      2144-02-06 10:07:00   40  \n",
      "4      2132-12-20 12:07:00   35  \n",
      "6      2155-05-14 19:50:00   45  \n",
      "...                    ...  ...  \n",
      "30682  2150-03-22 23:59:00   20  \n",
      "30683  2148-12-18 22:20:00   20  \n",
      "30684  2144-03-07 21:51:00   20  \n",
      "30686  2171-09-12 19:03:00   20  \n",
      "30687  2171-10-04 19:10:00   20  \n",
      "\n",
      "[6632 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "LVEF_under_50 = LVEF_under_50.drop(['note_type', 'note_seq'], axis=1)\n",
    "print(LVEF_under_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92990c0d-da5e-4a3d-a330-34afb2240c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              note_id  subject_id   hadm_id            charttime  \\\n",
      "0      10002495-DS-13    10002495  24982426  2141-05-29 00:00:00   \n",
      "1      10004235-DS-21    10004235  24181354  2196-03-04 00:00:00   \n",
      "2      10004401-DS-27    10004401  29988601  2144-02-06 00:00:00   \n",
      "4      10005817-DS-11    10005817  20626031  2132-12-20 00:00:00   \n",
      "6      10010471-DS-21    10010471  21322534  2155-05-10 00:00:00   \n",
      "...               ...         ...       ...                  ...   \n",
      "30682  19769933-DS-16    19769933  26578430  2150-03-22 00:00:00   \n",
      "30683   19810932-DS-3    19810932  29764035  2148-12-18 00:00:00   \n",
      "30684  19818243-DS-19    19818243  25296595  2144-03-07 00:00:00   \n",
      "30686  19993336-DS-11    19993336  24615303  2171-09-12 00:00:00   \n",
      "30687  19993336-DS-12    19993336  23077223  2171-10-04 00:00:00   \n",
      "\n",
      "                 storetime LVEF  \n",
      "0      2141-05-30 02:29:00   35  \n",
      "1      2196-03-06 10:57:00   25  \n",
      "2      2144-02-06 10:07:00   40  \n",
      "4      2132-12-20 12:07:00   35  \n",
      "6      2155-05-14 19:50:00   45  \n",
      "...                    ...  ...  \n",
      "30682  2150-03-22 23:59:00   20  \n",
      "30683  2148-12-18 22:20:00   20  \n",
      "30684  2144-03-07 21:51:00   20  \n",
      "30686  2171-09-12 19:03:00   20  \n",
      "30687  2171-10-04 19:10:00   20  \n",
      "\n",
      "[6632 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "LVEF_under_50 = LVEF_under_50.rename(columns={\"text\": \"LVEF\"})\n",
    "print(LVEF_under_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b6bdf3-ab16-4217-b7e7-7d7e934a29fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject_id   hadm_id  seq_num icd_code  icd_version         note_id  \\\n",
      "0      10010471  29842315        5    I5033           10  10010471-DS-22   \n",
      "1      10014354  29600294        8    I5032           10  10014354-DS-20   \n",
      "2      10041599  22152209        3    42832            9   10041599-DS-6   \n",
      "3      10127936  20688231        1    42833            9  10127936-DS-21   \n",
      "4      10193065  23614190        8    I5032           10  10193065-DS-23   \n",
      "..          ...       ...      ...      ...          ...             ...   \n",
      "329    19794689  21650727        2    I5033           10   19794689-DS-2   \n",
      "330    19796013  24367668        6    42830            9  19796013-DS-13   \n",
      "331    19837737  21760644        2    42832            9  19837737-DS-10   \n",
      "332    19844485  26525497        2    42831            9  19844485-DS-20   \n",
      "333    19913743  27776081        2    42832            9   19913743-DS-5   \n",
      "\n",
      "               charttime            storetime LVEF   stay_id  \\\n",
      "0    2155-12-07 00:00:00  2155-12-09 10:22:00   25  32119961   \n",
      "1    2148-08-18 00:00:00  2148-08-19 07:19:00   40  39864867   \n",
      "2    2122-08-27 00:00:00  2122-09-07 13:26:00   45  34813591   \n",
      "3    2165-10-14 00:00:00  2165-10-14 13:52:00   45  39916050   \n",
      "4    2129-01-01 00:00:00  2129-01-04 07:14:00   40  35158537   \n",
      "..                   ...                  ...  ...       ...   \n",
      "329  2162-08-22 00:00:00  2162-08-25 21:14:00   20  39580728   \n",
      "330  2147-06-04 00:00:00  2147-06-04 18:02:00   50  39076122   \n",
      "331  2140-02-27 00:00:00  2140-02-28 15:58:00   45  36530812   \n",
      "332  2184-03-15 00:00:00  2184-03-16 03:12:00   50  35995326   \n",
      "333  2131-02-04 00:00:00  2131-02-05 21:22:00   40  32445761   \n",
      "\n",
      "                                       first_careunit  \\\n",
      "0                            Coronary Care Unit (CCU)   \n",
      "1    Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "2                            Coronary Care Unit (CCU)   \n",
      "3        Cardiac Vascular Intensive Care Unit (CVICU)   \n",
      "4                  Medical Intensive Care Unit (MICU)   \n",
      "..                                                ...   \n",
      "329                          Coronary Care Unit (CCU)   \n",
      "330  Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "331                          Coronary Care Unit (CCU)   \n",
      "332               Surgical Intensive Care Unit (SICU)   \n",
      "333                          Coronary Care Unit (CCU)   \n",
      "\n",
      "                                        last_careunit               intime  \\\n",
      "0                            Coronary Care Unit (CCU)  2155-12-02 20:33:00   \n",
      "1    Medical/Surgical Intensive Care Unit (MICU/SICU)  2148-08-16 08:57:26   \n",
      "2                            Coronary Care Unit (CCU)  2122-08-24 11:22:04   \n",
      "3        Cardiac Vascular Intensive Care Unit (CVICU)  2165-10-10 09:07:56   \n",
      "4                  Medical Intensive Care Unit (MICU)  2128-12-27 17:18:00   \n",
      "..                                                ...                  ...   \n",
      "329                          Coronary Care Unit (CCU)  2162-08-16 02:52:00   \n",
      "330  Medical/Surgical Intensive Care Unit (MICU/SICU)  2147-05-12 20:29:45   \n",
      "331                          Coronary Care Unit (CCU)  2140-02-21 11:03:45   \n",
      "332               Surgical Intensive Care Unit (SICU)  2184-03-10 14:08:00   \n",
      "333                          Coronary Care Unit (CCU)  2131-02-02 10:57:07   \n",
      "\n",
      "                 outtime        los  \n",
      "0    2155-12-07 18:19:18   4.907153  \n",
      "1    2148-08-17 14:45:17   1.241562  \n",
      "2    2122-08-26 10:34:03   1.966655  \n",
      "3    2165-10-13 14:44:28   3.233704  \n",
      "4    2128-12-30 02:47:12   2.395278  \n",
      "..                   ...        ...  \n",
      "329  2162-08-19 19:02:41   3.674086  \n",
      "330  2147-06-04 17:22:07  22.869699  \n",
      "331  2140-02-23 21:28:49   2.434074  \n",
      "332  2184-03-13 16:26:03   3.095868  \n",
      "333  2131-02-03 12:36:17   1.068866  \n",
      "\n",
      "[334 rows x 15 columns] 334\n"
     ]
    }
   ],
   "source": [
    "# Filter diagnoses for relevant ICD codes\n",
    "heart_failure_patients = diagnoses[diagnoses[\"icd_code\"].isin(['I5030', '42830', 'I5031', '42831', 'I5032', '42832', 'I5033', '42833'])]\n",
    "\n",
    "# Merge with LVEF\n",
    "LVEF_patients = heart_failure_patients.merge(LVEF_under_50, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "# Merge with ICU stays\n",
    "hf_icu = LVEF_patients.merge(icustays, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "\n",
    "# Extract unique ICU stay IDs\n",
    "icu_ids = hf_icu[\"stay_id\"].unique()\n",
    "print(hf_icu, len(icu_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e72bff3a-c71f-4432-89fc-58c2cf9b328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ICU IDs: [32119961 39864867 34813591 39916050 35158537 35988506 35149906 36650825\n",
      " 33976285 36275744 37484032 31615601 39064261 36007916 37066577 32115746\n",
      " 37690238 36206974 30574839 38056861 37980262 39946294 30047110 35378572\n",
      " 37759830 38571466 32863045 37223807 30240703 39557479 30326504 33272807\n",
      " 36839738 34903620 35406666 37339173 32357993 32970582 34755431 30721603\n",
      " 31132542 37858317 36516295 37548793 39082582 38768353 35013417 33870823\n",
      " 38961723 36159356 30548119 31394901 33493059 38268460 39406417 31601830\n",
      " 36713654 35967314 37723752 36112143 34043983 38389114 39147811 39055079\n",
      " 32216303 36030807 32106452 31653741 37074647 30792513 31305394 38083052\n",
      " 36547334 31901817 34867699 36912772 39817695 36117858 31195920 35816578\n",
      " 37854747 36713694 39702238 37684007 34746182 32764204 30654462 38560404\n",
      " 36738588 32659288 34904311 38558137 39612812 30828325 30166913 34425328\n",
      " 31558480 34645917 30056217 37128514 38845954 38425787 37201080 39026094\n",
      " 38236288 33155235 37936337 33312436 30574776 32051933 34190051 32674481\n",
      " 38853473 36706168 33997144 36340523 36043488 34288539 37951452 39059460\n",
      " 33328533 38315403 35189239 32328739 39246133 37410117 34803462 32376597\n",
      " 39089938 31324303 32008643 31582323 33341439 30332706 31353449 37684512\n",
      " 30657692 39576383 37403398 39139102 38256455 37419369 32001348 33608017\n",
      " 39486015 37763148 32871627 32675115 31541089 35190303 30478425 36724149\n",
      " 36813532 35431459 35192641 32469379 32901301 33599940 33551009 36789416\n",
      " 38915478 31382344 38169072 31238006 37182286 34294474 34383756 35315529\n",
      " 38994436 34287071 36605227 36804135 34161082 32179784 35213792 38189018\n",
      " 34990210 30479872 34686682 33567039 32004548 30239763 36513004 39920049\n",
      " 36148606 36613308 36798053 36661850 39233416 39571806 37477345 38468262\n",
      " 31794250 37713811 39610103 30366562 32070899 39456919 30690523 34373782\n",
      " 39630025 39020324 37563506 35478985 39975647 39583388 31533526 37936344\n",
      " 33976289 38204550 39042841 31498470 36828715 32289131 32030984 33930375\n",
      " 37854345 34997263 34683600 38614028 33822668 37001541 37860617 33713546\n",
      " 34887890 32032750 33311871 33093962 36469210 32649454 32354110 31956936\n",
      " 37061440 36384306 35336680 35309044 33127178 37486870 38541339 30662162\n",
      " 36706796 36871481 37732942 33838551 33416444 34844718 30508966 32454627\n",
      " 37464758 35418905 36301711 31377653 39323401 32324375 33610637 33072529\n",
      " 39202616 37538416 39811676 31544321 33404297 37459500 30748856 31708767\n",
      " 35160914 39784673 38978159 32413574 31874793 36115505 34709240 33545369\n",
      " 38360216 36222534 36845808 38913968 37815113 38486997 37810579 30403003\n",
      " 34194133 32985137 34704529 35120621 30348068 32673164 38002541 36314419\n",
      " 35438659 39104319 36936972 36898646 34243434 38222542 38856107 38566987\n",
      " 36892867 39765292 38552190 39297004 34508161 35577582 38729671 30078205\n",
      " 36526457 35574998 39670622 30529524 30101365 34251146 38955855 39722153\n",
      " 31713528 38930399 37006047 39526126 38227029 39098499 37961326 38410305\n",
      " 31471308 30634259 33576993 33366208 34565195 38193913 38339923 37046850\n",
      " 35072138 39580728 39076122 36530812 35995326 32445761]\n",
      "Number of unique ICU IDs: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
      "/tmp/ipykernel_7416/74789829.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved with 146090 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Load relevant data\\nchunk_size = 1000  # Adjust the chunk size based on your available memory\\nvitals_list = []\\nfor chunk in pd.read_csv(\"icu/chartevents.csv\", chunksize=chunk_size):\\n    #chunk_filtered = chunk[(chunk[\"stay_id\"].isin(icu_ids)) & (chunk[\"itemid\"].isin(itemid_map.values()))]\\n    #vitals_list.append(chunk_filtered)\\n    #print(vitals_list)\\n    print(chunk)\\n\\n# Concatenate all filtered chunks\\nvitals = pd.concat(vitals_list, ignore_index=True)\\nprint(vitals)  # Check if the vitals dataframe is populated\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define ITEMIDs for relevant vitals (e.g., Heart Rate, BP, SpO2)\n",
    "# Define ITEMIDs for vitals and labs\n",
    "itemid_map = {\n",
    "    \"Heart Rate\": 220045,\n",
    "    \"Systolic BP\": 220179,\n",
    "    \"Diastolic BP\": 220180,\n",
    "    \"SpO2\": 220277,\n",
    "    \"Temperature\": 223761,\n",
    "    \"BMI\": 226512,\n",
    "    \"Bicarbonate\": 227443,\n",
    "    \"Creatinine\": 220615,\n",
    "    \"Hemoglobin\": 220228,\n",
    "    \"INR(PT)\": 220562,\n",
    "    \"Platelet Count\": 227457,\n",
    "    \"Potassium\": 220640,\n",
    "    \"WBC Count\": 220546,\n",
    "    \"Sodium\": 220645,\n",
    "    \"NT-proBNP\": 227444,\n",
    "    \"Troponin T\": 227429\n",
    "}\n",
    "\n",
    "# Check unique values for 'stay_id' and 'itemid' in a sample chunk\n",
    "vitals_list = []\n",
    "print(\"Unique ICU IDs:\", icu_ids)\n",
    "print(f\"Number of unique ICU IDs: {len(icu_ids)}\")\n",
    "\n",
    "# Define chunk size\n",
    "usecols = [\"stay_id\", \"subject_id\", \"hadm_id\", \"charttime\", \"itemid\", \"valuenum\"]\n",
    "chunk_size = 5000  # Reduce if memory issues persist\n",
    "filtered_rows = []\n",
    "\n",
    "# Process the file in smaller chunks\n",
    "with pd.read_csv(\"icu/chartevents.csv\", usecols=usecols, chunksize=chunk_size) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"])  # Convert datetime in chunks\n",
    "        chunk_filtered = chunk[\n",
    "            chunk[\"stay_id\"].isin(icu_ids) & chunk[\"itemid\"].isin(itemid_map.values())\n",
    "        ]\n",
    "        if not chunk_filtered.empty:\n",
    "            filtered_rows.append(chunk_filtered)\n",
    "\n",
    "# Concatenate filtered chunks if any data exists\n",
    "if filtered_rows:\n",
    "    vitals = pd.concat(filtered_rows, ignore_index=True)\n",
    "    vitals.to_csv(\"filtered_vitals.csv\", index=False)\n",
    "    print(f\"Filtered data saved with {len(vitals)} rows.\")\n",
    "else:\n",
    "    print(\"No matching data found.\")\n",
    "\n",
    "'''\n",
    "# Load relevant data\n",
    "chunk_size = 1000  # Adjust the chunk size based on your available memory\n",
    "vitals_list = []\n",
    "for chunk in pd.read_csv(\"icu/chartevents.csv\", chunksize=chunk_size):\n",
    "    #chunk_filtered = chunk[(chunk[\"stay_id\"].isin(icu_ids)) & (chunk[\"itemid\"].isin(itemid_map.values()))]\n",
    "    #vitals_list.append(chunk_filtered)\n",
    "    #print(vitals_list)\n",
    "    print(chunk)\n",
    "\n",
    "# Concatenate all filtered chunks\n",
    "vitals = pd.concat(vitals_list, ignore_index=True)\n",
    "print(vitals)  # Check if the vitals dataframe is populated\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69204d57-2c70-4f4b-b1b7-b687a4e6a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        subject_id   hadm_id   stay_id           charttime  itemid  valuenum\n",
      "0         10010471  29842315  32119961 2155-12-04 00:00:00  220045      73.0\n",
      "1         10010471  29842315  32119961 2155-12-04 00:00:00  220277      99.0\n",
      "2         10010471  29842315  32119961 2155-12-04 00:02:00  220179      89.0\n",
      "3         10010471  29842315  32119961 2155-12-04 00:02:00  220180      41.0\n",
      "4         10010471  29842315  32119961 2155-12-04 01:00:00  220045      80.0\n",
      "...            ...       ...       ...                 ...     ...       ...\n",
      "146085    19913743  27776081  32445761 2131-02-03 05:31:00  220645     139.0\n",
      "146086    19913743  27776081  32445761 2131-02-03 05:31:00  227443      23.0\n",
      "146087    19913743  27776081  32445761 2131-02-03 05:31:00  220228      12.1\n",
      "146088    19913743  27776081  32445761 2131-02-03 05:31:00  220546       7.6\n",
      "146089    19913743  27776081  32445761 2131-02-03 05:31:00  227457     181.0\n",
      "\n",
      "[146090 rows x 6 columns]\n",
      "Index(['subject_id', 'gender', 'anchor_age', 'anchor_year',\n",
      "       'anchor_year_group', 'dod'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vitals)\n",
    "print(patients.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "626d5414-abb4-422d-9f0b-5b187ba4c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add death labels\n",
    "admissions[\"admittime\"] = pd.to_datetime(admissions[\"admittime\"])\n",
    "admissions[\"dischtime\"] = pd.to_datetime(admissions[\"dischtime\"])\n",
    "admissions[\"deathtime\"] = pd.to_datetime(admissions[\"deathtime\"])\n",
    "\n",
    "# Calculate death flags\n",
    "admissions[\"death_within_30_days\"] = (\n",
    "    (admissions[\"deathtime\"] - admissions[\"admittime\"]).dt.days <= 30\n",
    ") & admissions[\"deathtime\"].notnull()\n",
    "\n",
    "admissions[\"death_within_1_year\"] = (\n",
    "    (admissions[\"deathtime\"] - admissions[\"admittime\"]).dt.days <= 365\n",
    ") & admissions[\"deathtime\"].notnull()\n",
    "\n",
    "# Calculate age\n",
    "patients[\"anchor_year\"] = pd.to_numeric(patients[\"anchor_year\"], errors=\"coerce\")\n",
    "patients[\"anchor_age\"] = pd.to_numeric(patients[\"anchor_age\"], errors=\"coerce\")\n",
    "patients[\"age_admission\"] = patients[\"anchor_age\"]  # or join using admittime year if needed\n",
    "\n",
    "# Merge patient demographics with ICU data\n",
    "demo = admissions.merge(patients[[\"subject_id\", \"gender\", \"anchor_age\"]], on=\"subject_id\", how=\"left\")\n",
    "demo = demo[[\"subject_id\", \"hadm_id\", \"death_within_30_days\", \"death_within_1_year\", \"anchor_age\", \"gender\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43e02354-2b21-4c81-90ad-bd89eda7b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map itemids to feature names\n",
    "itemid_reverse_map = {v: k for k, v in itemid_map.items()}\n",
    "vitals[\"label\"] = vitals[\"itemid\"].map(itemid_reverse_map)\n",
    "\n",
    "# Sort and pivot\n",
    "vitals.sort_values(by=[\"stay_id\", \"charttime\"], inplace=True)\n",
    "vitals_pivoted = vitals.pivot_table(\n",
    "    index=[\"stay_id\", \"charttime\"],\n",
    "    columns=\"label\",\n",
    "    values=\"valuenum\"\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70cc441c-2a11-4498-a980-d659b640b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample at hourly intervals per ICU stay\n",
    "vitals_pivoted['charttime'] = pd.to_datetime(vitals_pivoted['charttime'])\n",
    "vitals_hourly = (\n",
    "    vitals_pivoted\n",
    "    .groupby(\"stay_id\", group_keys=False)\n",
    "    .apply(lambda x: x.set_index(\"charttime\").resample(\"1H\").mean().ffill(limit=6))\n",
    "    .reset_index()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df5a742-3917-4a52-9456-ac152edddce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge LVEF + ICU + demo\n",
    "full = hf_icu.merge(demo, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "full = full.merge(LVEF_under_50[[\"subject_id\", \"hadm_id\", \"LVEF\"]], on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "\n",
    "# Merge with time-series vitals\n",
    "final_dataset = vitals_hourly.merge(full, on=\"stay_id\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "211dcb12-55ae-4f56-9e1e-b24100aa1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in final_dataset:\n",
      "['charttime_x', 'stay_id', 'BMI', 'Bicarbonate', 'Creatinine', 'Diastolic BP', 'Heart Rate', 'Hemoglobin', 'NT-proBNP', 'Platelet Count', 'Sodium', 'SpO2', 'Systolic BP', 'Temperature', 'Troponin T', 'WBC Count', 'subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'charttime_y', 'storetime', 'LVEF_x', 'first_careunit', 'last_careunit', 'intime', 'outtime', 'los', 'death_within_30_days', 'death_within_1_year', 'anchor_age', 'gender', 'LVEF_y']\n",
      "              charttime_x     stay_id       BMI  Bicarbonate  Creatinine  \\\n",
      "10    2170-03-05 00:00:00  30056217.0  0.069288          NaN         NaN   \n",
      "11    2170-03-05 01:00:00  30056217.0  0.069288          NaN         NaN   \n",
      "12    2170-03-05 02:00:00  30056217.0  0.069288          NaN         NaN   \n",
      "13    2170-03-05 03:00:00  30056217.0  0.069288          NaN         NaN   \n",
      "14    2170-03-05 04:00:00  30056217.0  0.069288     0.355556        0.25   \n",
      "...                   ...         ...       ...          ...         ...   \n",
      "35743 2192-10-02 09:00:00  39920049.0       NaN          NaN         NaN   \n",
      "35744 2192-10-02 10:00:00  39920049.0       NaN          NaN         NaN   \n",
      "35745 2192-10-02 11:00:00  39920049.0       NaN          NaN         NaN   \n",
      "35746 2192-10-02 12:00:00  39920049.0       NaN          NaN         NaN   \n",
      "35747 2192-10-02 13:00:00  39920049.0       NaN          NaN         NaN   \n",
      "\n",
      "       Diastolic BP  Heart Rate  Hemoglobin  NT-proBNP  Platelet Count  ...  \\\n",
      "10              NaN         NaN         NaN        NaN             NaN  ...   \n",
      "11             30.5    0.421053         NaN        NaN             NaN  ...   \n",
      "12             25.0    0.468421         NaN        NaN             NaN  ...   \n",
      "13             26.0    0.436842         NaN        NaN             NaN  ...   \n",
      "14             26.0    0.447368         NaN        NaN             NaN  ...   \n",
      "...             ...         ...         ...        ...             ...  ...   \n",
      "35743          65.0    0.531579         NaN        NaN             NaN  ...   \n",
      "35744          67.0    0.510526         NaN        NaN             NaN  ...   \n",
      "35745          64.0    0.526316         NaN        NaN             NaN  ...   \n",
      "35746          68.0    0.531579         NaN        NaN             NaN  ...   \n",
      "35747          20.0    0.328947         NaN        NaN             NaN  ...   \n",
      "\n",
      "                                         first_careunit  \\\n",
      "10                             Coronary Care Unit (CCU)   \n",
      "11                             Coronary Care Unit (CCU)   \n",
      "12                             Coronary Care Unit (CCU)   \n",
      "13                             Coronary Care Unit (CCU)   \n",
      "14                             Coronary Care Unit (CCU)   \n",
      "...                                                 ...   \n",
      "35743  Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "35744  Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "35745  Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "35746  Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "35747  Medical/Surgical Intensive Care Unit (MICU/SICU)   \n",
      "\n",
      "                                          last_careunit               intime  \\\n",
      "10                             Coronary Care Unit (CCU)  2170-03-05 00:30:01   \n",
      "11                             Coronary Care Unit (CCU)  2170-03-05 00:30:01   \n",
      "12                             Coronary Care Unit (CCU)  2170-03-05 00:30:01   \n",
      "13                             Coronary Care Unit (CCU)  2170-03-05 00:30:01   \n",
      "14                             Coronary Care Unit (CCU)  2170-03-05 00:30:01   \n",
      "...                                                 ...                  ...   \n",
      "35743  Medical/Surgical Intensive Care Unit (MICU/SICU)  2192-09-22 02:56:52   \n",
      "35744  Medical/Surgical Intensive Care Unit (MICU/SICU)  2192-09-22 02:56:52   \n",
      "35745  Medical/Surgical Intensive Care Unit (MICU/SICU)  2192-09-22 02:56:52   \n",
      "35746  Medical/Surgical Intensive Care Unit (MICU/SICU)  2192-09-22 02:56:52   \n",
      "35747  Medical/Surgical Intensive Care Unit (MICU/SICU)  2192-09-22 02:56:52   \n",
      "\n",
      "                   outtime        los  death_within_30_days  \\\n",
      "10     2170-03-15 10:22:34  10.411493                  True   \n",
      "11     2170-03-15 10:22:34  10.411493                  True   \n",
      "12     2170-03-15 10:22:34  10.411493                  True   \n",
      "13     2170-03-15 10:22:34  10.411493                  True   \n",
      "14     2170-03-15 10:22:34  10.411493                  True   \n",
      "...                    ...        ...                   ...   \n",
      "35743  2192-10-02 15:48:37  10.535937                  True   \n",
      "35744  2192-10-02 15:48:37  10.535937                  True   \n",
      "35745  2192-10-02 15:48:37  10.535937                  True   \n",
      "35746  2192-10-02 15:48:37  10.535937                  True   \n",
      "35747  2192-10-02 15:48:37  10.535937                  True   \n",
      "\n",
      "       death_within_1_year  anchor_age  gender LVEF_y  \n",
      "10                    True          55       M     40  \n",
      "11                    True          55       M     40  \n",
      "12                    True          55       M     40  \n",
      "13                    True          55       M     40  \n",
      "14                    True          55       M     40  \n",
      "...                    ...         ...     ...    ...  \n",
      "35743                 True          66       F     50  \n",
      "35744                 True          66       F     50  \n",
      "35745                 True          66       F     50  \n",
      "35746                 True          66       F     50  \n",
      "35747                 True          66       F     50  \n",
      "\n",
      "[4161 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "print(\"Columns in final_dataset:\")\n",
    "print(final_dataset.columns.tolist())\n",
    "features = [\n",
    "    \"Heart Rate\", \"Systolic BP\", \"SpO2\", \"Temperature\", \"BMI\",\n",
    "    \"Bicarbonate\", \"Creatinine\", \"Hemoglobin\",\n",
    "    \"Platelet Count\", \"WBC Count\", \"Sodium\",\n",
    "    \"NT-proBNP\", \"Troponin T\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "final_dataset[features] = scaler.fit_transform(final_dataset[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30962b-0bcf-424e-92bf-12d2a4559ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"final_heart_failure_timeseries.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4081750-66de-466a-9410-02fde3e1292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 24  # hours\n",
    "segments = []\n",
    "\n",
    "for stay_id, group in final_dataset.groupby(\"stay_id\"):\n",
    "    if len(group) >= window_size:\n",
    "        segment = group.iloc[:window_size]\n",
    "        segments.append(segment)\n",
    "\n",
    "# This produces a list of time-series windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2481d0d-226a-4cd3-977a-a3b0705a0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08acd04-7b4f-47da-9660-8b5a673998cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07191681-03ca-4025-8c69-eaba34b2ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         subject_id   hadm_id   stay_id           charttime  itemid  valuenum  \\\n",
      "0          12106780  25661012  37081503 2110-02-04 10:31:00  226512      69.3   \n",
      "1          12106780  25661012  37081503 2110-02-04 12:19:00  220277     100.0   \n",
      "2          12106780  25661012  37081503 2110-02-04 12:19:00  220045      77.0   \n",
      "3          12106780  25661012  37081503 2110-02-04 12:25:00  223761      97.5   \n",
      "4          12106780  25661012  37081503 2110-02-04 12:25:00  220045      80.0   \n",
      "...             ...       ...       ...                 ...     ...       ...   \n",
      "1077706    14288592  28211733  31011820 2209-03-24 19:02:00  220180      75.0   \n",
      "1077707    14288592  28211733  31011820 2209-03-24 20:00:00  220277      94.0   \n",
      "1077708    14288592  28211733  31011820 2209-03-24 20:00:00  220045      94.0   \n",
      "1077709    14288592  28211733  31011820 2209-03-24 20:02:00  220180      79.0   \n",
      "1077710    14288592  28211733  31011820 2209-03-24 20:02:00  220179     152.0   \n",
      "\n",
      "        gender note_id storetime LVEF  \n",
      "0            M     NaN       NaN  NaN  \n",
      "1            M     NaN       NaN  NaN  \n",
      "2            M     NaN       NaN  NaN  \n",
      "3            M     NaN       NaN  NaN  \n",
      "4            M     NaN       NaN  NaN  \n",
      "...        ...     ...       ...  ...  \n",
      "1077706      F     NaN       NaN  NaN  \n",
      "1077707      F     NaN       NaN  NaN  \n",
      "1077708      F     NaN       NaN  NaN  \n",
      "1077709      F     NaN       NaN  NaN  \n",
      "1077710      F     NaN       NaN  NaN  \n",
      "\n",
      "[1077711 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure LVEF data is in datetime format and sorted\n",
    "LVEF_all[\"charttime\"] = pd.to_datetime(LVEF_all[\"charttime\"])\n",
    "vitals = vitals.sort_values(\"charttime\")\n",
    "LVEF_all = LVEF_all.sort_values(\"charttime\")\n",
    "\n",
    "# Merge vitals with gender data\n",
    "vitals = vitals.merge(patients, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# Merge on closest timestamp using backward fill\n",
    "LVEF_vitals_merged = pd.merge_asof(\n",
    "    vitals,\n",
    "    LVEF_all,\n",
    "    on=\"charttime\",\n",
    "    by=[\"subject_id\", \"hadm_id\"],\n",
    "    direction=\"backward\"\n",
    ")\n",
    "\n",
    "# Forward-fill LVEF values for each subject\n",
    "LVEF_vitals_merged[\"LVEF\"] = LVEF_vitals_merged.groupby(\"subject_id\")[\"LVEF\"].ffill()\n",
    "\n",
    "'''\n",
    "# Convert charttime to datetime\n",
    "vitals[\"charttime\"] = pd.to_datetime(vitals[\"charttime\"])\n",
    "LVEF_all[\"charttime\"] = pd.to_datetime(LVEF_all[\"charttime\"])\n",
    "\n",
    "# Sort by charttime (required for merge_asof)\n",
    "vitals = vitals.sort_values(\"charttime\")\n",
    "LVEF_all = LVEF_all.sort_values(\"charttime\")\n",
    "\n",
    "print(LVEF_all)\n",
    "\n",
    "# Merge on the closest (previous) timestamp\n",
    "LVEF_vitals_merged = pd.merge_asof(\n",
    "    vitals,  # Larger dataframe (vitals)\n",
    "    LVEF_all,  # LVEF dataframe (smaller)\n",
    "    on=\"charttime\",\n",
    "    by=[\"subject_id\", \"hadm_id\"],  # Match on subject & admission ID\n",
    "    direction=\"backward\"  # Use \"nearest\" or \"forward\" if needed\n",
    ")\n",
    "\n",
    "LVEF_vitals_merged[\"LVEF\"] = LVEF_vitals_merged.groupby(\"subject_id\")[\"LVEF\"].ffill()\n",
    "\n",
    "'''\n",
    "\n",
    "print(LVEF_vitals_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "601dc6da-b4de-4b8a-8332-270b8ae0c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 charttime  subject_id     stay_id  220045  220179  220180  \\\n",
      "0      2186-03-20 00:00:00  12168737.0  30001336.0    70.5   110.0    52.0   \n",
      "1      2186-03-20 01:00:00  12168737.0  30001336.0    68.5   116.0    61.0   \n",
      "2      2186-03-20 02:00:00  12168737.0  30001336.0    57.0   104.0    55.0   \n",
      "3      2186-03-20 03:00:00  12168737.0  30001336.0    55.0   110.0    68.0   \n",
      "4      2186-03-20 04:00:00  12168737.0  30001336.0    63.0   104.0    59.0   \n",
      "...                    ...         ...         ...     ...     ...     ...   \n",
      "274929 2112-12-13 15:00:00  18570637.0  39990748.0    71.0   128.0    49.0   \n",
      "274930 2112-12-13 16:00:00  18570637.0  39990748.0    71.0   114.0    44.0   \n",
      "274931 2112-12-13 17:00:00  18570637.0  39990748.0    73.0   134.0    67.0   \n",
      "274932 2112-12-13 18:00:00  18570637.0  39990748.0    68.0   130.0    53.0   \n",
      "274933 2112-12-13 19:00:00  18570637.0  39990748.0    74.0   137.0    54.0   \n",
      "\n",
      "        220228  220277  220546  220615  220645  223761  226512  227429  \\\n",
      "0          8.9    96.0     9.0     1.1   131.0    98.5    77.0    1.60   \n",
      "1          8.9    96.5     9.0     1.1   131.0    98.5    77.0    1.60   \n",
      "2          8.9    97.0     9.0     1.1   131.0    98.5    77.0    1.60   \n",
      "3          8.9    97.0     9.0     1.1   131.0    98.5    77.0    1.60   \n",
      "4          8.9    99.0     9.0     1.1   131.0    98.5    77.0    1.60   \n",
      "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "274929     8.7    93.0     8.4     0.9   146.0    97.6     NaN    0.27   \n",
      "274930     8.7    93.0     8.4     0.9   146.0    97.8     NaN    0.27   \n",
      "274931     8.7    91.0     8.4     0.9   146.0    97.8     NaN    0.27   \n",
      "274932     8.7    92.0     8.4     0.9   146.0    97.8     NaN    0.20   \n",
      "274933     8.7    87.0     8.4     0.9   146.0    97.8     NaN    0.20   \n",
      "\n",
      "        227443  227444  227457 gender  \n",
      "0         22.0     NaN   163.0      M  \n",
      "1         22.0     NaN   163.0      M  \n",
      "2         22.0     NaN   163.0      M  \n",
      "3         22.0     NaN   163.0      M  \n",
      "4         22.0     NaN   163.0      M  \n",
      "...        ...     ...     ...    ...  \n",
      "274929    16.0     NaN   164.0      F  \n",
      "274930    16.0     NaN   164.0      F  \n",
      "274931    16.0     NaN   164.0      F  \n",
      "274932    16.0     NaN   164.0      F  \n",
      "274933    16.0     NaN   164.0      F  \n",
      "\n",
      "[274934 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pivot the table to get a time series per patient\n",
    "LVEF_vitals_pivot = LVEF_vitals_merged.pivot_table(\n",
    "    index=[\"subject_id\", \"stay_id\", \"charttime\"], \n",
    "    columns=\"itemid\", \n",
    "    values=\"valuenum\"\n",
    ")\n",
    "\n",
    "# Reset column names and index\n",
    "LVEF_vitals_pivot.columns = [str(col) for col in LVEF_vitals_pivot.columns]\n",
    "LVEF_vitals_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Resample to hourly data\n",
    "LVEF_vitals_resampled = (\n",
    "    LVEF_vitals_pivot.groupby(\"stay_id\", group_keys=False)\n",
    "    .apply(lambda group: group.set_index(\"charttime\").resample(\"1H\").mean().ffill())\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge gender back after pivoting\n",
    "LVEF_vitals_resampled = LVEF_vitals_resampled.merge(patients, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# Drop unnecessary columns if they exist\n",
    "LVEF_vitals_resampled.drop([\"caregiver_id\", \"warning\", \"note_id\"], axis=1, inplace=True, errors=\"ignore\")\n",
    "\n",
    "'''\n",
    "LVEF_vitals = vitals.merge(LVEF_all, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "print(LVEF_vitals)\n",
    "\n",
    "LVEF_vitals[\"charttime_x\"] = pd.to_datetime(LVEF_vitals[\"charttime_x\"])\n",
    "LVEF_vitals[\"storetime_x\"] = pd.to_datetime(LVEF_vitals[\"storetime_x\"])\n",
    "\n",
    "# Pivot table: each ITEMID becomes a separate column\n",
    "LVEF_vitals_pivot = LVEF_vitals.pivot_table(index=[\"subject_id\", \"stay_id\", \"charttime_x\"], columns=\"itemid\", values=\"valuenum\")\n",
    "\n",
    "# Reset column names\n",
    "LVEF_vitals_pivot.columns = [str(col) for col in LVEF_vitals_pivot.columns]\n",
    "\n",
    "# Reset index\n",
    "LVEF_vitals_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Resample to hourly data (forward fill missing values)\n",
    "LVEF_vitals_resampled = (\n",
    "    LVEF_vitals_pivot.groupby(\"stay_id\", group_keys=False)\n",
    "    .apply(lambda group: group.reset_index().set_index(\"charttime_x\").resample(\"1H\").mean().ffill())\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "LVEF_vitals_resampled.drop([\"caregiver_id\", \"warning\", \"note_id\"], axis=1, inplace=True, errors=\"ignore\")\n",
    "'''\n",
    "print(LVEF_vitals_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2b9a4-db6b-423d-9c98-985da4e035c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daf537d7-7b4a-4fcb-b70a-77a7c856d486",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar for large operations\n",
    "\n",
    "# Load core tables\n",
    "admissions = pd.read_csv(\"hosp/admissions.csv\")\n",
    "patients = pd.read_csv(\"hosp/patients.csv\")\n",
    "diagnoses = pd.read_csv(\"hosp/diagnoses_icd.csv\")\n",
    "icustays = pd.read_csv(\"icu/icustays.csv\")\n",
    "chartevents = pd.read_csv(\"icu/chartevents.csv\", chunksize=250000)  # Adjusted chunk size\n",
    "labevents = pd.read_csv(\"hosp/labevents.csv\")\n",
    "discharge = pd.read_csv(\"discharge.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6da5d970-1fc1-4d96-b21c-4bb678052b17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [subject_id, hadm_id, stay_id, caregiver_id, charttime, storetime, itemid, value, valuenum, valueuom, warning]\n",
      "Index: []                note_id  subject_id   hadm_id  charttime            storetime  \\\n",
      "66243   12024697-DS-11    12024697  20302177 2110-01-15  2110-01-19 10:31:00   \n",
      "268863  18106347-DS-15    18106347  24305596 2110-01-15  2110-01-15 11:25:00   \n",
      "73953   12257372-DS-21    12257372  23964251 2110-01-19  2110-01-19 11:53:00   \n",
      "291493  18780420-DS-10    18780420  28977824 2110-01-22  2110-01-22 15:30:00   \n",
      "158399  14779071-DS-15    14779071  20963511 2110-01-22  2110-01-22 12:54:00   \n",
      "...                ...         ...       ...        ...                  ...   \n",
      "124701  13774741-DS-10    13774741  27575074 2210-07-23  2210-07-24 23:12:00   \n",
      "184399  15566010-DS-10    15566010  29192759 2210-09-11  2210-09-12 15:03:00   \n",
      "77247    12352097-DS-8    12352097  23434751 2210-10-04  2210-10-05 15:48:00   \n",
      "105230   13184296-DS-3    13184296  28785633 2211-05-07  2211-05-09 09:40:00   \n",
      "171307  15173387-DS-18    15173387  25336001 2211-06-23  2211-06-24 19:34:00   \n",
      "\n",
      "                                                     text  LVEF  \n",
      "66243    \\nName:  ___              Unit No:   ___\\n \\n...   521  \n",
      "268863   \\nName:  ___                  Unit No:   ___\\...    29  \n",
      "73953    \\nName:  ___                Unit ___:   ___\\n...    36  \n",
      "291493   \\nName:  ___                  Unit No:   ___\\...  1700  \n",
      "158399   \\nName:  ___                  Unit No:   ___\\...     4  \n",
      "...                                                   ...   ...  \n",
      "124701   \\nName:  ___               Unit No:   ___\\n \\...    35  \n",
      "184399   \\nName:  ___                Unit No:   ___\\n ...    40  \n",
      "77247    \\nName:  ___                  Unit No:   ___\\...   250  \n",
      "105230   \\nName:  ___                    Unit No:   __...     5  \n",
      "171307   \\nName:  ___.              Unit No:   ___\\n \\...    45  \n",
      "\n",
      "[50894 rows x 7 columns]\n",
      "Empty DataFrame\n",
      "Columns: [subject_id, stay_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(vitals, LVEF)\n",
    "# Merge admissions for age and mortality\n",
    "admissions[\"admission_year\"] = pd.to_datetime(admissions[\"admittime\"]).dt.year\n",
    "patients[\"dod\"] = pd.to_datetime(patients[\"dod\"], errors=\"coerce\")\n",
    "admissions[\"admittime\"] = pd.to_datetime(admissions[\"admittime\"])\n",
    "admissions[\"dischtime\"] = pd.to_datetime(admissions[\"dischtime\"])\n",
    "admissions = admissions.merge(\n",
    "    patients[[\"subject_id\", \"anchor_age\", \"anchor_year\", \"dod\"]],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_patient\")  # Avoids _x and _y issues\n",
    ")\n",
    "admissions[\"dod\"] = pd.to_datetime(admissions[\"dod\"], errors=\"coerce\")  # Convert to datetime\n",
    "admissions[\"dod\"] = admissions[\"dod\"].fillna(pd.Timestamp.max)  # Replace NaN with future date\n",
    "admissions[\"death_within_30_days\"] = ((admissions[\"dischtime\"] + pd.Timedelta(days=30)) >= admissions[\"dod\"]).astype(int)\n",
    "admissions[\"death_within_1_year\"] = ((admissions[\"dischtime\"] + pd.Timedelta(days=365)) >= admissions[\"dod\"]).astype(int)\n",
    "admissions[\"age_admission\"] = admissions[\"anchor_age\"] + (admissions[\"admission_year\"] - admissions[\"anchor_year\"])\n",
    "\n",
    "# Merge vitals with LVEF (closest previous measurement)\n",
    "vitals.sort_values(\"charttime\", inplace=True)\n",
    "LVEF.sort_values(\"charttime\", inplace=True)\n",
    "LVEF_vitals = pd.merge_asof(vitals, LVEF, on=\"charttime\", by=[\"subject_id\", \"hadm_id\"], direction=\"backward\")\n",
    "\n",
    "# Forward-fill missing LVEF values per patient\n",
    "LVEF_vitals[\"LVEF\"] = LVEF_vitals.groupby(\"subject_id\")[\"LVEF\"].ffill()\n",
    "\n",
    "# Merge with admissions\n",
    "LVEF_vitals = LVEF_vitals.merge(admissions, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "\n",
    "# Pivot to create time-series structure\n",
    "LVEF_vitals_pivot = LVEF_vitals.pivot_table(index=[\"subject_id\", \"stay_id\", \"charttime\"], columns=\"itemid\", values=\"valuenum\")\n",
    "LVEF_vitals_pivot.columns = [str(col) for col in LVEF_vitals_pivot.columns]\n",
    "LVEF_vitals_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Resample to hourly intervals\n",
    "LVEF_vitals_pivot[\"charttime\"] = pd.to_datetime(LVEF_vitals_pivot[\"charttime\"])\n",
    "\n",
    "# Resample to hourly intervals (without resetting index yet)\n",
    "LVEF_vitals_resampled = (\n",
    "    LVEF_vitals_pivot\n",
    "    .set_index(\"charttime\")  # Ensure charttime is the index\n",
    "    .groupby(\"stay_id\", group_keys=False)\n",
    "    .resample(\"1H\")  # Resample to 1 hour intervals\n",
    "    .mean()  # Compute the mean for each hour\n",
    "    .ffill()  # Forward-fill missing values\n",
    ")\n",
    "\n",
    "# Optimize memory usage\n",
    "LVEF_vitals_resampled = LVEF_vitals_resampled.astype({col: \"float32\" for col in LVEF_vitals_resampled.columns if col not in [\"subject_id\", \"stay_id\", \"charttime\"]})\n",
    "\n",
    "print(LVEF_vitals_resampled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8f013a7-40bb-4454-9c5b-f2804ea1f4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chartevents: 1732it [09:23,  3.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Normalize ICD codes\n",
    "diagnoses[\"icd_code\"] = diagnoses[\"icd_code\"].str.replace(\".\", \"\", regex=True)\n",
    "\n",
    "# Define relevant ICD codes\n",
    "hf_icd_codes = {\"I5030\", \"42830\", \"I5031\", \"42831\", \"I5032\", \"42832\", \"I5033\", \"42833\"}\n",
    "\n",
    "# Filter diagnoses for heart failure\n",
    "heart_failure_patients = diagnoses[diagnoses[\"icd_code\"].isin(hf_icd_codes)]\n",
    "\n",
    "# Function to extract LVEF values from text\n",
    "def extract_lvef(text):\n",
    "    match = re.search(r'(\\d+)', text)\n",
    "    return int(match.group(1)) if match else np.nan\n",
    "\n",
    "# Process LVEF values\n",
    "LVEF = discharge[discharge['text'].str.contains(r'LVEF', na=False)].copy()\n",
    "LVEF[\"LVEF\"] = LVEF[\"text\"].apply(extract_lvef)\n",
    "LVEF.dropna(subset=[\"LVEF\"], inplace=True)\n",
    "LVEF = LVEF.drop(columns=[\"note_type\", \"note_seq\"], errors='ignore')\n",
    "\n",
    "# Merge LVEF with heart failure patients\n",
    "LVEF_patients = heart_failure_patients.merge(LVEF, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "\n",
    "# Merge with ICU stays\n",
    "hf_icu = LVEF_patients.merge(icustays, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "\n",
    "# Extract ICU stay IDs\n",
    "icu_ids = set(hf_icu[\"stay_id\"].unique())\n",
    "\n",
    "# Define ITEMIDs for vitals and labs\n",
    "itemid_map = {\n",
    "    \"Heart Rate\": 220045,\n",
    "    \"Systolic BP\": 220179,\n",
    "    \"Diastolic BP\": 220180,\n",
    "    \"SpO2\": 220277,\n",
    "    \"Temperature\": 223761,\n",
    "    \"BMI\": 226512,\n",
    "    \"Bicarbonate\": 227443,\n",
    "    \"Creatinine\": 220615,\n",
    "    \"Hemoglobin\": 220228,\n",
    "    \"INR(PT)\": 220562,\n",
    "    \"Platelet Count\": 227457,\n",
    "    \"Potassium\": 220640,\n",
    "    \"WBC Count\": 220546,\n",
    "    \"Sodium\": 220645,\n",
    "    \"NT-proBNP\": 227444,\n",
    "    \"Troponin T\": 227429\n",
    "}\n",
    "\n",
    "# Process chartevents in chunks\n",
    "vitals_list = []\n",
    "for chunk in tqdm(chartevents, desc=\"Processing chartevents\"):\n",
    "    chunk_filtered = chunk[(chunk[\"stay_id\"].isin(icu_ids)) & (chunk[\"itemid\"].isin(itemid_map.values()))]\n",
    "    vitals_list.append(chunk_filtered)\n",
    "\n",
    "# Concatenate all vitals data\n",
    "vitals = pd.concat(vitals_list, ignore_index=True)\n",
    "\n",
    "# Convert timestamps\n",
    "vitals[\"charttime\"] = pd.to_datetime(vitals[\"charttime\"])\n",
    "LVEF[\"charttime\"] = pd.to_datetime(LVEF[\"charttime\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b6cf4-583a-4246-9691-14fa8ba5b702",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23f8a3-932f-48dd-902f-e2a71b95a073",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
